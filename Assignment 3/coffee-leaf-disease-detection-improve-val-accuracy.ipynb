{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nimport cv2\nimport os\n\n# Define dataset paths\ndataset_path = '/kaggle/input/coffee-leaf-disease-akash/CoLeaf DATASET'\ncategories = os.listdir(dataset_path)\nnum_classes = len(categories)\n\n# Load images and labels\ndef load_data():\n    images = []\n    labels = []\n    for label, category in enumerate(categories):\n        category_path = os.path.join(dataset_path, category)\n        for root, _, files in os.walk(category_path):\n            for img_name in files:\n                img_path = os.path.join(root, img_name)\n                img = cv2.imread(img_path)\n                if img is not None:\n                    img = cv2.resize(img, (224, 224))  # Resize images to 224x224\n                    images.append(img)\n                    labels.append(label)\n                else:\n                    print(f\"Failed to load image: {img_path}\")\n    return np.array(images), np.array(labels)\n\nimages, labels = load_data()\n\n# Ensure that we have loaded images\nif len(images) == 0:\n    raise Exception(\"No images loaded. Check dataset path and image files.\")\n\n# Normalize the pixel values\nimages = images / 255.0\n\n# Convert labels to one-hot encoding\nlabels = to_categorical(labels, num_classes)\n\n# Data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2,\n    shear_range=0.2,\n    fill_mode='nearest'\n)\n\n# Define the MobileNetV2 model with regularization\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\ndef create_mobilenetv2_model(input_shape, num_classes):\n    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)  # Regularization\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    \n    for layer in base_model.layers:\n        layer.trainable = False\n\n    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Implementing K-fold Cross-Validation\nkf = KFold(n_splits=3, shuffle=True, random_state=42)\nfold_no = 1\n\nfor train_index, val_index in kf.split(images):\n    print(f'Training on fold {fold_no}...')\n    X_train, X_val = images[train_index], images[val_index]\n    y_train, y_val = labels[train_index], labels[val_index]\n    \n    mobilenetv2_model = create_mobilenetv2_model(input_shape=(224, 224, 3), num_classes=num_classes)\n    \n    # Define callbacks\n    callbacks = [\n        ModelCheckpoint(f'mobilenetv2_best_model_fold_{fold_no}.keras', save_best_only=True, monitor='val_accuracy', mode='max'),\n        EarlyStopping(monitor='val_accuracy', mode='max', patience=5, verbose=1)\n    ]\n    \n    # Train the model\n    history = mobilenetv2_model.fit(\n        datagen.flow(X_train, y_train, batch_size=32),\n        validation_data=(X_val, y_val),\n        epochs=10,\n        callbacks=callbacks\n    )\n    \n    # Evaluate the model\n    scores = mobilenetv2_model.evaluate(X_val, y_val, verbose=0)\n    print(f'Score for fold {fold_no}: {mobilenetv2_model.metrics_names[0]} of {scores[0]}; {mobilenetv2_model.metrics_names[1]} of {scores[1]}')\n    \n    fold_no += 1\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-19T14:40:06.024491Z","iopub.execute_input":"2024-05-19T14:40:06.024902Z","iopub.status.idle":"2024-05-19T14:48:22.732327Z","shell.execute_reply.started":"2024-05-19T14:40:06.024871Z","shell.execute_reply":"2024-05-19T14:48:22.731149Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Training on fold 1...\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:33\u001b[0m 20s/step - accuracy: 0.0312 - loss: 3.0008","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1716129790.595935     103 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1716129790.633159     103 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m13/21\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.2313 - loss: 2.7549 ","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716129802.917361     105 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 678ms/step - accuracy: 0.2722 - loss: 2.5526","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716129808.024292     104 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1716129813.717435     105 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.2801 - loss: 2.5138 - val_accuracy: 0.4970 - val_loss: 1.3802\nEpoch 2/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - accuracy: 0.5234 - loss: 1.4263 - val_accuracy: 0.5238 - val_loss: 1.3297\nEpoch 3/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 277ms/step - accuracy: 0.5749 - loss: 1.1950 - val_accuracy: 0.5655 - val_loss: 1.3152\nEpoch 4/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 259ms/step - accuracy: 0.6066 - loss: 1.1062 - val_accuracy: 0.5595 - val_loss: 1.1978\nEpoch 5/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 258ms/step - accuracy: 0.6243 - loss: 1.0864 - val_accuracy: 0.5536 - val_loss: 1.1883\nEpoch 6/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 275ms/step - accuracy: 0.6526 - loss: 1.0195 - val_accuracy: 0.5952 - val_loss: 1.1424\nEpoch 7/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 260ms/step - accuracy: 0.6308 - loss: 0.9889 - val_accuracy: 0.5298 - val_loss: 1.2515\nEpoch 8/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 257ms/step - accuracy: 0.6411 - loss: 1.0164 - val_accuracy: 0.5685 - val_loss: 1.2842\nEpoch 9/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 256ms/step - accuracy: 0.6644 - loss: 0.8889 - val_accuracy: 0.5536 - val_loss: 1.2808\nEpoch 10/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 255ms/step - accuracy: 0.6981 - loss: 0.8806 - val_accuracy: 0.5506 - val_loss: 1.2371\nScore for fold 1: loss of 1.2371357679367065; compile_metrics of 0.550595223903656\nTraining on fold 2...\nEpoch 1/10\n\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:02\u001b[0m 12s/step - accuracy: 0.1250 - loss: 2.7810","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716129902.275919     104 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m12/21\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.2141 - loss: 2.8943 ","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716129914.337350     103 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 685ms/step - accuracy: 0.2588 - loss: 2.6511","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716129919.296111     104 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.2667 - loss: 2.6069 - val_accuracy: 0.5254 - val_loss: 1.5823\nEpoch 2/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - accuracy: 0.4615 - loss: 1.4484 - val_accuracy: 0.5731 - val_loss: 1.4026\nEpoch 3/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 274ms/step - accuracy: 0.5621 - loss: 1.3663 - val_accuracy: 0.5791 - val_loss: 1.2143\nEpoch 4/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 261ms/step - accuracy: 0.6329 - loss: 1.1336 - val_accuracy: 0.5731 - val_loss: 1.1931\nEpoch 5/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 266ms/step - accuracy: 0.6079 - loss: 1.0998 - val_accuracy: 0.5761 - val_loss: 1.2586\nEpoch 6/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 255ms/step - accuracy: 0.6595 - loss: 0.9768 - val_accuracy: 0.5731 - val_loss: 1.1599\nEpoch 7/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 277ms/step - accuracy: 0.6465 - loss: 1.0508 - val_accuracy: 0.6537 - val_loss: 1.0788\nEpoch 8/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 252ms/step - accuracy: 0.6837 - loss: 0.9498 - val_accuracy: 0.6060 - val_loss: 1.0924\nEpoch 9/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 261ms/step - accuracy: 0.6792 - loss: 0.9296 - val_accuracy: 0.6299 - val_loss: 1.0135\nEpoch 10/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 259ms/step - accuracy: 0.6873 - loss: 0.8946 - val_accuracy: 0.6149 - val_loss: 1.0629\nScore for fold 2: loss of 1.0628889799118042; compile_metrics of 0.6149253845214844\nTraining on fold 3...\nEpoch 1/10\n\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:02\u001b[0m 12s/step - accuracy: 0.0625 - loss: 2.8380","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716130013.863925     106 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 7/21\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 856ms/step - accuracy: 0.1602 - loss: 2.7561","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716130018.922346     104 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.2647 - loss: 2.4898","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716130025.635820     103 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 719ms/step - accuracy: 0.2749 - loss: 2.4496 - val_accuracy: 0.4896 - val_loss: 1.3698\nEpoch 2/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 274ms/step - accuracy: 0.5510 - loss: 1.3672 - val_accuracy: 0.5433 - val_loss: 1.2608\nEpoch 3/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - accuracy: 0.5885 - loss: 1.1386 - val_accuracy: 0.5642 - val_loss: 1.2738\nEpoch 4/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 281ms/step - accuracy: 0.5849 - loss: 1.2146 - val_accuracy: 0.5940 - val_loss: 1.1521\nEpoch 5/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 280ms/step - accuracy: 0.6274 - loss: 1.0290 - val_accuracy: 0.6209 - val_loss: 1.1183\nEpoch 6/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 254ms/step - accuracy: 0.6059 - loss: 1.0817 - val_accuracy: 0.5910 - val_loss: 1.1638\nEpoch 7/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 255ms/step - accuracy: 0.6321 - loss: 1.0270 - val_accuracy: 0.6179 - val_loss: 1.0671\nEpoch 8/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 251ms/step - accuracy: 0.6526 - loss: 0.9141 - val_accuracy: 0.5851 - val_loss: 1.1271\nEpoch 9/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 255ms/step - accuracy: 0.6845 - loss: 0.9079 - val_accuracy: 0.6209 - val_loss: 1.0649\nEpoch 10/10\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 276ms/step - accuracy: 0.7153 - loss: 0.8269 - val_accuracy: 0.6448 - val_loss: 1.0508\nScore for fold 3: loss of 1.0507712364196777; compile_metrics of 0.6447761058807373\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom io import BytesIO\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nimport cv2\nimport os\ndataset_path = '/kaggle/input/coffee-leaf-disease-akash/CoLeaf DATASET'\n\n# Define dataset paths\ndir_list = ['boron-B',\n            'calcium-Ca',\n            'iron-Fe',\n            'magnesium-Mg',\n            'manganese-Mn',\n            'more-deficiencies',\n            'nitrogen-N',\n            'phosphorus-P',\n            'potasium-K']\n\n# Image data generator\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\n\n# Function to generate images and load them into memory\ndef generate_images_in_memory(kaggle_input_dir, num_images=500):\n    generated_images = datagen.flow_from_directory(\n        kaggle_input_dir,\n        batch_size=1,\n        class_mode=None,\n        shuffle=True\n    )\n    \n    images = []\n    for _ in range(num_images):\n        img_batch = next(generated_images)\n        img = img_batch[0].astype('uint8')  # Convert to uint8\n        _, buffer = cv2.imencode('.jpg', img)\n        img_bytes = BytesIO(buffer.tobytes())\n        img_array = cv2.imdecode(np.frombuffer(img_bytes.getvalue(), np.uint8), cv2.IMREAD_COLOR)\n        images.append(img_array)\n    \n    return images\n\n# Load and generate images for each class\nall_images = []\nall_labels = []\n\nfor label, classes in enumerate(dir_list):\n    kaggle_input_dir = f'/kaggle/input/coffee-leaf-disease-akash/CoLeaf DATASET/{classes}'\n    images = generate_images_in_memory(kaggle_input_dir)\n    labels = [label] * len(images)\n    \n    all_images.extend(images)\n    all_labels.extend(labels)\n\n# Convert to numpy arrays\nall_images = np.array(all_images)\nall_labels = np.array(all_labels)\n\n# Print the shapes to verify\nprint('Images shape:', all_images.shape)\nprint('Labels shape:', all_labels.shape)\n\n# Ensure that we have loaded images\nif len(all_images) == 0:\n    raise Exception(\"No images loaded. Check dataset path and image files.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:47:08.079788Z","iopub.execute_input":"2024-05-19T15:47:08.080610Z","iopub.status.idle":"2024-05-19T15:56:56.477646Z","shell.execute_reply.started":"2024-05-19T15:47:08.080565Z","shell.execute_reply":"2024-05-19T15:56:56.476369Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-19 15:47:13.081391: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-19 15:47:13.081514: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-19 15:47:13.257856: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 101 images belonging to 1 classes.\nFound 162 images belonging to 1 classes.\nFound 65 images belonging to 1 classes.\nFound 79 images belonging to 1 classes.\nFound 83 images belonging to 1 classes.\nFound 104 images belonging to 1 classes.\nFound 64 images belonging to 1 classes.\nFound 246 images belonging to 1 classes.\nFound 96 images belonging to 1 classes.\nImages shape: (4500, 256, 256, 3)\nLabels shape: (4500,)\n","output_type":"stream"}]},{"cell_type":"code","source":"categories = [d for d in os.listdir(dataset_path) if d in dir_list and os.path.isdir(os.path.join(dataset_path, d))]\nnum_classes = len(categories)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:56:56.480035Z","iopub.execute_input":"2024-05-19T15:56:56.481424Z","iopub.status.idle":"2024-05-19T15:56:56.487974Z","shell.execute_reply.started":"2024-05-19T15:56:56.481388Z","shell.execute_reply":"2024-05-19T15:56:56.486926Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"num_classes","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:56:56.489060Z","iopub.execute_input":"2024-05-19T15:56:56.489381Z","iopub.status.idle":"2024-05-19T15:56:56.502415Z","shell.execute_reply.started":"2024-05-19T15:56:56.489355Z","shell.execute_reply":"2024-05-19T15:56:56.501444Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"9"},"metadata":{}}]},{"cell_type":"code","source":"images = all_images / 255.0\n\n# Convert labels to one-hot encoding\nlabels = to_categorical(all_labels, num_classes)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:56:56.504827Z","iopub.execute_input":"2024-05-19T15:56:56.505199Z","iopub.status.idle":"2024-05-19T15:56:58.863034Z","shell.execute_reply.started":"2024-05-19T15:56:56.505166Z","shell.execute_reply":"2024-05-19T15:56:58.862008Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:42:37.884812Z","iopub.execute_input":"2024-05-19T15:42:37.885679Z","iopub.status.idle":"2024-05-19T15:42:37.892270Z","shell.execute_reply.started":"2024-05-19T15:42:37.885631Z","shell.execute_reply":"2024-05-19T15:42:37.891116Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(4500, 9)"},"metadata":{}}]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2,\n    shear_range=0.2,\n    fill_mode='nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:56:58.864312Z","iopub.execute_input":"2024-05-19T15:56:58.864630Z","iopub.status.idle":"2024-05-19T15:56:58.870376Z","shell.execute_reply.started":"2024-05-19T15:56:58.864602Z","shell.execute_reply":"2024-05-19T15:56:58.869040Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\ndef create_mobilenetv2_model(input_shape, num_classes):\n    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)  # Regularization\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    \n    for layer in base_model.layers:\n        layer.trainable = False\n\n    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Implementing K-fold Cross-Validation\nkf = KFold(n_splits=3, shuffle=True, random_state=42)\nfold_no = 1\n\nfor train_index, val_index in kf.split(images):\n    print(f'Training on fold {fold_no}...')\n    X_train, X_val = images[train_index], images[val_index]\n    y_train, y_val = labels[train_index], labels[val_index]\n    \n    mobilenetv2_model = create_mobilenetv2_model(input_shape=(256, 256, 3), num_classes=num_classes)\n    \n    # Define callbacks\n    callbacks = [\n        ModelCheckpoint(f'mobilenetv2_best_model_fold_{fold_no}.keras', save_best_only=True, monitor='val_accuracy', mode='max'),\n        EarlyStopping(monitor='val_accuracy', mode='max', patience=5, verbose=1)\n    ]\n    \n    # Train the model\n    history = mobilenetv2_model.fit(\n        datagen.flow(X_train, y_train, batch_size=32),\n        validation_data=(X_val, y_val),\n        epochs=30,\n        callbacks=callbacks\n    )\n    \n    # Evaluate the model\n    scores = mobilenetv2_model.evaluate(X_val, y_val, verbose=0)\n    print(f'Score for fold {fold_no}: {mobilenetv2_model.metrics_names[0]} of {scores[0]}; {mobilenetv2_model.metrics_names[1]} of {scores[1]}')\n    \n    fold_no += 1\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:56:58.871897Z","iopub.execute_input":"2024-05-19T15:56:58.872277Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Training on fold 1...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_762/2591423959.py:9: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 2/94\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.1094 - loss: 2.6959  ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1716134246.658325     871 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1716134246.693998     871 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m38/94\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 665ms/step - accuracy: 0.2425 - loss: 2.4289","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716134271.210888     870 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - accuracy: 0.3301 - loss: 2.0690","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716134300.939980     868 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1716134310.036039     868 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 687ms/step - accuracy: 0.3322 - loss: 2.0605 - val_accuracy: 0.5867 - val_loss: 1.1618\nEpoch 2/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 444ms/step - accuracy: 0.5553 - loss: 1.2658 - val_accuracy: 0.6113 - val_loss: 1.0648\nEpoch 3/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 445ms/step - accuracy: 0.6144 - loss: 1.1035 - val_accuracy: 0.6600 - val_loss: 0.9587\nEpoch 4/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 445ms/step - accuracy: 0.6149 - loss: 1.0666 - val_accuracy: 0.6653 - val_loss: 0.9263\nEpoch 5/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 438ms/step - accuracy: 0.6351 - loss: 1.0253 - val_accuracy: 0.6767 - val_loss: 0.9015\nEpoch 6/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 435ms/step - accuracy: 0.6388 - loss: 0.9819 - val_accuracy: 0.6647 - val_loss: 0.9265\nEpoch 7/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 440ms/step - accuracy: 0.6612 - loss: 0.9174 - val_accuracy: 0.7127 - val_loss: 0.8056\nEpoch 8/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 434ms/step - accuracy: 0.6604 - loss: 0.9101 - val_accuracy: 0.6847 - val_loss: 0.8503\nEpoch 9/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 445ms/step - accuracy: 0.6671 - loss: 0.8872 - val_accuracy: 0.7240 - val_loss: 0.7807\nEpoch 10/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 443ms/step - accuracy: 0.6912 - loss: 0.8318 - val_accuracy: 0.7213 - val_loss: 0.7700\nEpoch 11/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 442ms/step - accuracy: 0.7085 - loss: 0.8012 - val_accuracy: 0.7247 - val_loss: 0.7595\nEpoch 12/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 446ms/step - accuracy: 0.6983 - loss: 0.8443 - val_accuracy: 0.7300 - val_loss: 0.7459\nEpoch 13/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 434ms/step - accuracy: 0.6894 - loss: 0.8466 - val_accuracy: 0.7113 - val_loss: 0.7730\nEpoch 14/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 445ms/step - accuracy: 0.7205 - loss: 0.7578 - val_accuracy: 0.7553 - val_loss: 0.6939\nEpoch 15/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 441ms/step - accuracy: 0.7232 - loss: 0.7524 - val_accuracy: 0.7320 - val_loss: 0.7105\nEpoch 16/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 439ms/step - accuracy: 0.7259 - loss: 0.7304 - val_accuracy: 0.7480 - val_loss: 0.6850\nEpoch 17/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 438ms/step - accuracy: 0.7224 - loss: 0.7320 - val_accuracy: 0.7493 - val_loss: 0.7010\nEpoch 18/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 445ms/step - accuracy: 0.7477 - loss: 0.6847 - val_accuracy: 0.7387 - val_loss: 0.7067\nEpoch 19/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 439ms/step - accuracy: 0.7352 - loss: 0.7115 - val_accuracy: 0.7580 - val_loss: 0.6660\nEpoch 20/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 443ms/step - accuracy: 0.7288 - loss: 0.7085 - val_accuracy: 0.7600 - val_loss: 0.6854\nEpoch 21/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 438ms/step - accuracy: 0.7365 - loss: 0.7050 - val_accuracy: 0.7700 - val_loss: 0.6524\nEpoch 22/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 435ms/step - accuracy: 0.7663 - loss: 0.6525 - val_accuracy: 0.7647 - val_loss: 0.6470\nEpoch 23/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 437ms/step - accuracy: 0.7543 - loss: 0.6636 - val_accuracy: 0.7720 - val_loss: 0.6317\nEpoch 24/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 434ms/step - accuracy: 0.7481 - loss: 0.6764 - val_accuracy: 0.7553 - val_loss: 0.6881\nEpoch 25/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 440ms/step - accuracy: 0.7591 - loss: 0.6643 - val_accuracy: 0.7787 - val_loss: 0.6168\nEpoch 26/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 440ms/step - accuracy: 0.7920 - loss: 0.5864 - val_accuracy: 0.7253 - val_loss: 0.7369\nEpoch 27/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 444ms/step - accuracy: 0.7612 - loss: 0.6312 - val_accuracy: 0.7820 - val_loss: 0.6003\nEpoch 28/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 439ms/step - accuracy: 0.7697 - loss: 0.5992 - val_accuracy: 0.7720 - val_loss: 0.6157\nEpoch 29/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 442ms/step - accuracy: 0.7669 - loss: 0.6278 - val_accuracy: 0.7820 - val_loss: 0.5961\nEpoch 30/30\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 443ms/step - accuracy: 0.7911 - loss: 0.5754 - val_accuracy: 0.7860 - val_loss: 0.5987\nScore for fold 1: loss of 0.5987476706504822; compile_metrics of 0.7860000133514404\nTraining on fold 2...\n","output_type":"stream"}]}]}